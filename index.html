<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="index_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.555">

  <meta name="author" content="Valentin Patilea^\dagger">
  <meta name="author" content="Jeffrey S. Racine^\ddagger">
  <title>quarto-input38793b0b</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="custom.css">
  <link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script>
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
  </script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title"><div class="line-block">Locally Adaptive Online<br>
Functional Data Analysis</div></h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Valentin Patilea<span class="math inline">\(^\dagger\)</span> 
</div>
        <p class="quarto-title-affiliation">
            ENSAI &amp; CREST<span class="math inline">\(^\dagger\)</span>, valentin.patilea@ensai.fr
          </p>
    </div>
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Jeffrey S. Racine<span class="math inline">\(^\ddagger\)</span> 
</div>
        <p class="quarto-title-affiliation">
            McMaster University<span class="math inline">\(^\ddagger\)</span>, racinej@mcmaster.ca
          </p>
    </div>
</div>

  <p class="date">Tuesday, June 25, 2024</p>
</section>
<section id="slide-pro-tips" class="title-slide slide level1 center">
<h1>Slide Pro-Tips</h1>
<div>
<ul>
<li><p>Link to slides - <a href="https://jeffreyracine.github.io/Braga">jeffreyracine.github.io/Braga</a> (case sensitive, <a href="https://jeffreyracine-github-io.translate.goog/Braga/?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en&amp;_x_tr_pto=wapp#/title-slide">Google Translate</a>)</p></li>
<li><p>View <strong>full screen</strong> by pressing the F key (press the Esc key to revert)</p></li>
<li><p>Access <strong>navigation menu</strong> by pressing the M key (click X in navigation menu to close)</p></li>
<li><p><strong>Advance</strong> using arrow keys</p></li>
<li><p><strong>Zoom</strong> in by holding down the Alt key in MS Windows, Opt key in macOS or Ctrl key in Linux, and clicking on any screen element (Alt/Opt/Ctrl click again to zoom out)</p>
<!--

- Use **copy to clipboard** button for R code blocks (upper right in block) to copy and paste into R/RStudio

--></li>
<li><p><strong>Export to a PDF</strong> by pressing the E key (wait a few seconds, then print [or print using system dialog], enable landscape layout, then save as PDF - press the E key to revert)</p></li>
<li><p>Enable drawing tools - chalk <strong>board</strong> by pressing the B key (B to revert), notes <strong>canvas</strong> by pressing the C key (C to revert), press the Del key to erase, press the D key to <strong>download drawings</strong></p></li>
</ul>
</div>
<aside class="notes">
<p>Encourage participants to print/save a PDF copy of the slides as there is no guarantee that this material will be there when they realize it might be useful</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="abstract" class="title-slide slide level1 center">
<h1>Abstract</h1>
<p>One drawback with classical smoothing methods (kernels, splines, wavelets etc.) is their reliance on assuming the degree of smoothness (and thereby assuming continuous differentiability up to some order) for the underlying object being estimated. However, the underlying object may in fact be irregular (i.e., non-smooth and even perhaps nowhere differentiable) and, as well, the (ir)regularity of the underlying function may vary across its support. Elaborate adaptive methods for curve estimation have been proposed, however, their intrinsic complexity presents a formidable and perhaps even insurmountable barrier to their widespread adoption by practitioners. We contribute to the functional data literature by providing a pointwise MSE-optimal, data-driven, iterative plug-in estimator of “local regularity” and a computationally attractive, recursive, online updating method. In so doing we are able to separate measurement error “noise” from “irregularity” thanks to “replication”, a hallmark of functional data. Our results open the door for the construction of minimax optimal rates, “honest” confidence intervals, and the like, for various quantities of interest.</p>
</section>

<section>
<section id="outline-of-talk" class="title-slide slide level1 center">
<h1>Outline of Talk</h1>
<div>
<ul>
<li><p>Modern data is often <em>functional</em> in nature (e.g., an electrocardiogram (ECG) and many other measures recorded by wearable devices)</p></li>
<li><p>The analysis of functional data requires <em>nonparametric methods</em></p></li>
<li><p>However, nonparametric methods rely on <em>smoothness assumptions</em> (i.e., require you to assume something we don’t know)</p></li>
<li><p>We show how we can learn the degree of (non)smoothness in functional data settings and we separate this from <em>measurement noise</em> (this cannot be done with classical data)</p></li>
<li><p>This allows us to conduct functional data analysis that is optimal (we do this in a statistical framework)</p></li>
<li><p>We emphasize <em>online</em> computation (i.e., how to update when new functional data becomes available)</p></li>
</ul>
</div>
<aside class="notes">
<ul>
<li><p>Present overview of slides</p></li>
<li><p>Mention appendices and extra material (don’t be fooled by slide numbers - for your leisure not to be covered in the allotted time)</p></li>
<li><p>Presuming some may be unfamiliar with functional data elements, start with classical versus function sample elements</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classical-versus-functional-data" class="slide level2 center">
<h2>Classical Versus Functional Data</h2>
<ul>
<li class="fragment"><p>A <strong>defining feature of classical regression analysis</strong> is that</p>
<ul>
<li class="fragment"><p><strong>sample elements are random pairs</strong>, <span class="math inline">\((y_i,x_i)\)</span></p></li>
<li class="fragment"><p>the <em>function of interest</em> <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span> is <em>non-random</em></p></li>
</ul></li>
<li class="fragment"><p>A <strong>defining feature of functional data analysis </strong> is that</p>
<ul>
<li class="fragment"><p><strong>sample elements are random functions</strong>, <span class="math inline">\(X^{(i)}\)</span></p></li>
<li class="fragment"><p>these are <em>also functions of interest</em></p></li>
</ul></li>
<li class="fragment"><p>The following figure (<a href="#/fig-sampleelements" class="quarto-xref">Figure&nbsp;1</a>) presents <span class="math inline">\(N=25\)</span> sample elements (classical left plot, functional right plot)</p></li>
</ul>
<aside class="notes">
<ul>
<li>Point out that we are really in quite a different world when dealing with functions and need to think carefully about the data generating process</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classical-versus-functional-data-1" class="slide level2 center">
<h2>Classical Versus Functional Data</h2>

<img data-src="index_files/figure-revealjs/fig-sampleelements-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;1: Classical Versus Functional Sample Elements (<span class="math inline">\(N=25\)</span>)
</p></section>
<section id="functional-data" class="slide level2 center">
<h2>Functional Data</h2>
<ul>
<li class="fragment"><p>FDA is <em>the statistical analysis of samples of curves</em> (i.e., samples of random variables taking values in spaces of functions)</p></li>
<li class="fragment"><p>FDA has heterogeneous, longitudinal aspects (“individual trajectories”)</p></li>
<li class="fragment"><p>Curves are continuums, so <em>we never know the curve values at all points</em></p>
<ul>
<li class="fragment"><p>The curves are <em>only available at discrete points</em> (e.g., <span class="math inline">\((Y^{(i)}_m , T^{(i)}_m) \in\mathbb R \times [0,1]\)</span>)</p></li>
<li class="fragment"><p>The points at which curves are available can <em>differ across curves</em></p></li>
<li class="fragment"><p>The curves may be <em>measured with error</em></p></li>
</ul></li>
<li class="fragment"><p>Consider measurements taken from 1 random curve:</p>
<ul>
<li class="fragment"><p><a href="#/fig-nonnoisyfuncall" class="quarto-xref">Figure&nbsp;2</a> is measured without error from an <em>irregular</em> curve</p></li>
<li class="fragment"><p><a href="#/fig-noisyfuncall" class="quarto-xref">Figure&nbsp;3</a> is measured with error from a <em>smooth</em> curve</p></li>
<li class="fragment"><p><a href="#/fig-mfbm" class="quarto-xref">Figure&nbsp;4</a> displays <em>varying</em> (ir)regularity <em>and</em> measurement noise</p></li>
</ul></li>
</ul>
<aside class="notes">
<ul>
<li><p>Stop at “The curves may be <em>measured with error</em>”</p></li>
<li><p>Screen mirror RStudio with manipulate_mfbr.R and walk through the issues</p></li>
<li><p>Then proceed to discuss what we know and don’t know and “crimes” (assuming smoothness)</p></li>
<li><p>Some researchers <span class="citation" data-cites="horvath_kokoszka:2012">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Horváth and Kokoszka 2012</a>)</span> presume the curves are measured <strong>without error</strong> at <em>any t</em> (unrealistic to say the least, all theory in 5 pages), i.e., they suppose they have the <em>true curves</em> at any point</p></li>
<li><p>Sometimes what people do in practice is a <strong>crime</strong>… they smooth discrete points with splines <em>then</em> <strong>proceed presuming they have the true curves</strong> (theory is blindly applied forgetting curves are not the true one - there is no theory on FPCA which corresponds to real data)</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="fda-sample-element-1-random-function" class="slide level2 center">
<h2>FDA Sample Element (1 Random Function)</h2>

<img data-src="index_files/figure-revealjs/fig-nonnoisyfuncall-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;2: Irregular Function, Data Measured Without Error
</p></section>
<section id="fda-sample-element-1-random-function-1" class="slide level2 center">
<h2>FDA Sample Element (1 Random Function)</h2>

<img data-src="index_files/figure-revealjs/fig-noisyfuncall-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;3: Regular Function, Noisy Data
</p></section>
<section id="fda-sample-element-1-random-function-2" class="slide level2 center">
<h2>FDA Sample Element (1 Random Function)</h2>

<img data-src="index_files/figure-revealjs/fig-mfbm-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;4: Irregular Function, Varying Regularity, Noisy Data
</p><aside class="notes">
<ul>
<li><p>Tell audience we will now look at two real-world datasets</p></li>
<li><p>The first is quite “smooth” looking</p></li>
<li><p>The second much less to</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="fda-sample-elements-random-functions" class="slide level2 center">
<h2>FDA Sample Elements (Random Functions)</h2>

<img data-src="index_files/figure-revealjs/fig-growth-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;5: Berkeley Growth Study Data
</p><aside class="notes">
<ul>
<li><p>Point out that the data is unevenly spaced</p></li>
<li><p>4 measurements years 1-2, 1 per year until 8, 2 per year thereafter</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="fda-sample-elements-random-functions-1" class="slide level2 center">
<h2>FDA Sample Elements (Random Functions)</h2>

<img data-src="index_files/figure-revealjs/fig-canWeather-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;6: Canadian Weather Study Data
</p><aside class="notes">
<ul>
<li><p>Point out that the data is evenly spaced</p></li>
<li><p>Curve less smooth than previous example</p></li>
<li><p>“Common design” (will come back to this)</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!--

## Modelling Functional Data

-   Why not use classical linear regression to model each curve?

    - it would be difficult to justify given the nature of the data

-   Why not use existing nonparametric methods to model each curve?

    - it would be hard to justify smoothness assumptions, for one

-   Why not use classical time series or longitudinal/panel analysis

    - the observed points may not be equally spaced

    - the various curves may not be sampled at the same time points

    - the observed points may not be stationary

-   *Ideally*, one would keep the observation unit as collected, and model data as realizations in a suitable space of objects (i.e., space of curves)

::: {.notes}
- Modern data often come in the form of curves (wearables, health measurements)

- Point out we need a new framework
:::

# Scope, Highlights, and Related Work

## Project Scope

-   We drill down on *unknown regularity of unknown functions*

-   We exploit a key feature of FDA, namely, *replication*

-   We use data-driven local nonparametric kernel methods

-   Our method adapts, *pointwise*, to

    -   the *local regularity* of the underlying process (i.e., the Hölder exponent $H_t$ defined shortly and to *measurement noise* (i.e., we are able to separate *noise* from *regularity* thanks to *replication*)

    -   the *purpose(s)* of estimation (i.e., $\mu(t)$ versus $\Gamma(s,t)$ defined shortly)

- Our method is computationally tractable:

    - we have processed millions of curves, each containing hundreds of sample points, on a laptop in real-time as new online data arrives
    
::: {.notes}
- If I were to coin a slogan for this talk, it would be "think vertically!"

- Replication can be further exploited (i.e. beyond existing uses)
:::


## Highlights and Related Work

-   We contribute to the literature by providing i) an MSE-optimal, data-driven, iterative plug-in estimator of local regularity and ii) a computationally attractive, recursive, online updating method

-   Related work includes

    -   @gloter_hoffmann:2007, who consider noisy measurements of *one* sample path from a scaled fractional Brownian motion (fBm) with unknown (*scalar*, i.e., *constant*) Hurst parameter and unknown scale with measurements on an equidistant grid and heteroscedastic noise

    -   @gini_nickl:2010, @cai_low_ma:2014, and @ray:2017, who consider the construction of confidence or credible sets for a single curve of unknown regularity (the latter in a Bayesian framework)

    -   @golovkine_klutchnikoff_patilea:2022, who propose a non-smoothing estimator for local regularity of the trajectories of a stochastic process using order statistics (they also adopt a smoothing component, but this relies on an unknown constant $K_0$)
    
-->
</section></section>
<section>
<section id="functional-data-setting" class="title-slide slide level1 center">
<h1>Functional Data Setting</h1>

</section>
<section id="functional-data-1" class="slide level2 center">
<h2>Functional Data</h2>
<ul>
<li class="fragment"><p>Functional data carry information <em>along</em> the curves and <em>among</em> the curves</p></li>
<li class="fragment"><p>Consider a second-order stochastic process with continuous trajectories, <span class="math inline">\(X = (X_t : t\in [0,1])\)</span></p></li>
<li class="fragment"><p>The mean and covariance functions are <span class="math display">\[\begin{equation*}
\mu(t) = \mathbb{E}(X_t)\text{ and } \Gamma (s,t) =  \mathbb{E}\left\{ [X_s - \mu(s)]  [X_t-\mu(t)]\right\},\, s,t\in [0,1]
\end{equation*}\]</span></p></li>
<li class="fragment"><p>The framework we consider is one where independent sample path realizations <span class="math inline">\(X^{(i)}\)</span>, <span class="math inline">\(i=1,2\ldots,N\)</span>, of <span class="math inline">\(X\)</span> are measured with error at <em>discrete</em> times</p></li>
<li class="fragment"><p>The data associated with the <span class="math inline">\(i\)</span>th sample path <span class="math inline">\(X^{(i)}\)</span> consists of the pairs <span class="math inline">\((Y^{(i)}_m , T^{(i)}_m) \in\mathbb R \times [0,1]\)</span> generated as <span class="math display">\[\begin{equation*}
Y^{(i)}_m = X^{(i)}(T^{(i)}_m) + \varepsilon^{(i)}_m,
\qquad 1\leq m \leq M_i
\end{equation*}\]</span></p></li>
</ul>
<aside class="notes">
<ul>
<li><p>In probability theory and related fields, a <strong>stochastic</strong> or <strong>random process</strong> is a mathematical object usually defined as a family of random variables.</p></li>
<li><p>The term <strong>random function</strong> is also used to refer to a stochastic or random process, because a stochastic process can also be interpreted as a <em>random element in a function space</em>. The terms stochastic process and random process are used interchangeably.</p></li>
<li><p>https://en.wikipedia.org/wiki/Stochastic_process</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!--

## Discrete Sample Points

-   Here, $M_i$ (number of discrete sample points for the $i$th curve) is an integer which can be non-random and common to several $X^{(i)}$, or an independent draw from some positive integer random variable drawn independently of $X$

-   The $T^{(i)}_m$ are the measurement times for $X^{(i)}$, which can be non-random, or be randomly drawn from some distribution, independently of $X$ and the $M_i$

-   The case where $T^{(i)}_m$ are the same for several $X^{(i)}$, and implicitly the $M_i$ are the same too, is the so-called "common design" case

-   The case where the $T^{(i)}_m$ are random is the so-called "independent design" case (our main focus lies here)

::: {.notes}
- For the theory, we have to let the number of curves $N$ and the expectation of $M_i$ increase, so the data is more like a triangular array (at least for the theory)
:::

-->
</section>
<section id="measurement-errors-and-design" class="slide level2 center">
<h2>Measurement Errors and Design</h2>
<ul>
<li class="fragment"><p>The <span class="math inline">\(\varepsilon^{(i)}_m\)</span> are measurement errors, and we allow <span class="math display">\[\begin{equation*}
\varepsilon^{(i)}_m = \sigma(T^{(i)}_m) e^{(i)}_m, \quad 1\leq m \leq  M_i
\end{equation*}\]</span></p></li>
<li class="fragment"><p>The <span class="math inline">\(e^{(i)}_m\)</span> are independent copies of a centred variable <span class="math inline">\(e\)</span> with unit variance, and <span class="math inline">\(\sigma(T^{(i)}_m)\)</span> is some unknown bounded function which accounts for possibly heteroscedastic measurement errors</p></li>
<li class="fragment"><p>Our approach applies to both <em>independent design</em> and <em>common design</em> cases</p></li>
<li class="fragment"><p>Relative to the number of curves, <span class="math inline">\(N\)</span>, the number of points per curve, <span class="math inline">\(M_i\)</span>, may be small (“sparse”) or large (“dense”)</p></li>
</ul>
<!--

## Estimation Grid, Batch/Online

-   Let $\mathcal T_0\subset [0,1]$ be a set of points of interest

-   Typically, $\mathcal T_0$ is a refined grid of equidistant points

-   We wish to estimate the following functions:

    -   $\mu(\cdot)$, $\sigma(\cdot)$, $f_T(\cdot)$ on $\mathcal T_0$

    -   $\Gamma(\cdot,\cdot)$ on $\mathcal T_0 \times \mathcal T_0$

-   We are also concerned with computational limitations frequently encountered in this framework (we propose a recursive solution via stochastic approximation algorithms)

-   We will be interested in updating estimates as new functional data arises ("online") as well as performing estimation on an existing set of curves ("batch")

-->
</section>
<section id="replication" class="slide level2 center">
<h2>Replication</h2>
<ul>
<li class="fragment"><p>One key distinguishing feature of FDA is that of “replication” (i.e., <em>common structure</em> among curves)</p></li>
<li class="fragment"><p>Essentially, there is prior information in the <span class="math inline">\(N-1\)</span> sample curves that can be exploited to learn about the <span class="math inline">\(N\)</span>th, which is <em>not</em> available in, say, classical regression analysis</p></li>
<li class="fragment"><p>This common structure can be exploited for a variety of purposes</p></li>
<li class="fragment"><p>For instance, it will allow us to obtain estimates of the <em>regularity</em> of the curves that may vary across their domain <span class="math inline">\(t\in[0,1]\)</span> (i.e., <em>local regularity</em> estimates)</p></li>
<li class="fragment"><p>This would not be possible in the classical nonparametric setting where we are restricted to a single curve only</p></li>
</ul>
</section></section>
<section>
<section id="local-regularity" class="title-slide slide level1 center">
<h1>Local Regularity</h1>
<aside class="notes">
<p>Q <em>Can you provide a definition of “irregular function”?</em></p>
<ul>
<li><p>“It’s our meaning.”</p></li>
<li><p>“If the function is non-differentiable, and it’s regularity (in the sense of Hölder continuity, where the exponent gives the regularity) can vary, we call that situation an irregular one”</p></li>
<li><p>“I do not have a definition of irregular, because”regular” is too vague.”</p></li>
<li><p>“It could be differentiable, Lipschitz continuous, Hölder continuous, analytic, etc, etc”</p></li>
<li><p>“Irregular is perhaps inappropriate for saying that the curves are not differentiable. <strong>Non-smooth is better</strong>.”</p></li>
<li><p>“But here we have the other aspect: the Hölder exponent H could vary. This means that <strong>we allow different degrees of non smoothness in different points</strong>. I think we may also call such process irregular. We then have to look at the local non-smoothness, and this is what we do because H is estimated in any point t.”</p></li>
<li><p>“So in some sense it is both non smooth and irregular.”</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="overview" class="slide level2 center">
<h2>Overview</h2>
<ul>
<li class="fragment"><p>“<strong>Smoothness</strong> […] such as the <strong>existence of continuous second derivatives</strong>, is <strong>often imposed for regularization</strong> and is especially useful if nonparametric smoothing techniques are employed, as is prevalent in FDA” <span class="citation" data-cites="wang_chiou_muller:2016">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Wang, Chiou, and Müller 2016</a>)</span></p></li>
<li class="fragment"><p>This is problematic since imposing an unknown (and global) degree of smoothness may be incompatible with the underlying stochastic process</p></li>
<li class="fragment"><p>A key feature of our approach is its data-driven locally adaptive nature</p></li>
<li class="fragment"><p>We consider a meaningful regularity concept for the data generating process based on probability theory</p></li>
<li class="fragment"><p>We propose simple estimates for <em>local regularity</em> and link process regularity to sample path regularity</p></li>
</ul>
<aside class="notes">
<ul>
<li><p>“[w]e make the assumption that the underlying process generating the data is smooth. The observed data are subject to measurement error that may mask this smoothness” <span class="citation" data-cites="levitin_et_al:2007">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Levitin et al. 2007</a>, pg. 137-138)</span></p></li>
<li><p>“The assumption that a certain number of derivatives exist has been used in most of the analyses that we have considered. In this way we stabilize estimated principal components, regression functions, monotone transformations, canonical weight functions, and linear differential operators.</p>
<p>Are there more general concepts of regularity that would aid FDA?” <span class="citation" data-cites="ramsay_silverman:2005">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Ramsay and Silverman 2005</a>, pg. 380)</span></p></li>
<li><p><em>minimax optimal rates for mean and covariance functions</em>, <span class="citation" data-cites="lepski_mammen_spokoiny:1997 cai_yuan:2011">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Lepski, Mammen, and Spokoiny 1997</a>; <a href="#/references-scrollable" role="doc-biblioref" onclick="">Cai and Yuan 2011</a>)</span>, Cai &amp; Yuam (2010, 11, 12) (see minute 23 of zoom video feb 28 2023)</p></li>
<li><p>An estimator (estimation rule) is called <strong>minimax</strong> if its <strong>maximal risk is minimal</strong> among all estimators. In a sense this means that it is an estimator which performs best in the worst possible case allowed in the problem</p></li>
<li><p><em>adaptive confidence bands for nonparametric regression</em> <span class="citation" data-cites="cai_low_ma:2014">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Cai, Low, and Ma 2014</a>)</span> “Ideally, an adaptive confidence band should have its size automatically adjusted to the smoothness of the underlying function, while maintaining a prespecified coverage probability. However as we shall show such a goal is impossible even for Lipschitz function classes and hence a new framework for investigating adaptive confidence bands is needed.”</p></li>
<li><p><em>decrease of the eigenvalues of the covariance operator, which impacts optimal rates for the regression</em>, for instance <span class="citation" data-cites="belhakem_et_al:2021 hall_horowitz:2007">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Belhakem et al. 2021</a>; <a href="#/references-scrollable" role="doc-biblioref" onclick="">Hall and Horowitz 2007</a>)</span> (people say “suppose we know the rate of decrease of the eigenvalues of the covariance matrix operator of the covariates, <span class="math inline">\(\alpha\)</span>, which are functional in this case, but this rate is exactly <span class="math inline">\(2H+1\)</span>, so if we know <span class="math inline">\(H\)</span> we know the rate - it is like saying we know there are two derivatives, we know the <span class="math inline">\(\alpha\)</span>… how do they know that? They don’t!”) (minute 30 in the zoom video)</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="definition" class="slide level2 center">
<h2>Definition</h2>
<ul>
<li class="fragment"><p>A key element of our approach is “local regularity”, which here is the largest order <em>fractional derivative</em> admitted by the sample paths of <span class="math inline">\(X\)</span> as measured by the value of <span class="math inline">\(H_t\)</span>, the “local Hölder exponent”, which may vary with <span class="math inline">\(t\)</span></p></li>
<li class="fragment"><p>More precisely, here “local regularity” is the largest value <span class="math inline">\(H_t\)</span> for which, uniformly with respect to <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> in a neighborhood of <span class="math inline">\(t\)</span>, the second order moment of <span class="math inline">\((X_u-X_v)/|u-v|^{H_t}\)</span> is finite</p></li>
<li class="fragment"><p>We can then assume <span class="math display">\[\begin{equation*}
  \mathbb{E}\left[(X_u-X_v)^2\right]\approx L_t^2|u-v|^{2H_t}
  \end{equation*}\]</span> when <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> lie in a neighborhood of <span class="math inline">\(t\)</span></p></li>
<li class="fragment"><p>If a function is smooth (i.e., continuously differentiable), then <span class="math inline">\(H_t=1\)</span>, otherwise the function is non-smooth with <span class="math inline">\(0&lt;H_t&lt;1\)</span></p></li>
<li class="fragment"><p>If a function is a constant function then <span class="math inline">\(L_t=0\)</span>, otherwise <span class="math inline">\(L_t&gt;0\)</span></p></li>
</ul>
<aside class="notes">
<ul>
<li><p>The second order moment of the <strong>increments</strong></p></li>
<li><p>People may say “for a Hölder condition we have inequality, but why do you remove the inequality condition and replace with equality” and the response is “because you need equality in order to get estimates for <span class="math inline">\(H\)</span> and <span class="math inline">\(L\)</span> (if no equality, forget it), but the <em>good news</em> is that almost all the processes you find in all the probability books do satisfy this with <em>almost equal</em> so in fact there is no loss in generality (e.g., derivatives, squares, log(1+…) for gaussian processes do satisfy this with equality) so this is not restrictive at all</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="definition-1" class="slide level2 center">
<h2>Definition</h2>
<ul>
<li class="fragment"><p>Let <span class="math inline">\([t-\Delta_*/2, t + \Delta_*/2] \cap [0,1]\)</span>, and define <span class="math display">\[\begin{align*}
  \theta(u,v) &amp;= \mathbb{E}\left[ (X_u-X_v)^{2} \right],
  \quad\text{ hence }\\
  \theta(u,v) &amp;\approx L_t^2 |u-v|^{2H_t} \quad \text{if }   |u-v| \text{ is small and close to }t
\end{align*}\]</span></p></li>
<li class="fragment"><p>Letting <span class="math inline">\(\Delta_* =2^{-1}e^{-\log(\bar M_i)^{1/3}}&gt;0\)</span>, <span class="math inline">\(t_1=t-\Delta_*/2\)</span>, <span class="math inline">\(t_3= t + \Delta_*/2\)</span>, and <span class="math inline">\(t_2=(t_1+t_3)/2\)</span> (the definition of <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_3\)</span> is adjusted in boundary regions), then we show that <span class="math display">\[\begin{equation*}
H_t \approx  \frac{\log(\theta(t_1,t_3)) - \log(\theta(t_1,t_2))}{2\log(2)} \quad \text{if }  |t_3-t_1| \text{ is small}
\end{equation*}\]</span></p></li>
<li class="fragment"><p>Moreover, <span class="math display">\[\begin{equation*}
L_t \approx \frac{\sqrt{\theta(t_1,t_3)}}{|t_1-t_3|^{H_t} } \quad \text{if }  |t_3-t_1| \text{ is small}
\end{equation*}\]</span></p></li>
</ul>
<aside class="notes">
<ul>
<li><p><span class="math inline">\(\Delta_*\)</span> should go to 0</p></li>
<li><p><span class="math inline">\(\Delta_*\)</span> to some power should be larger than the pre-smoothing error (pre-smoothing error should be negligible to <span class="math inline">\(\Delta\)</span> to some power)</p></li>
<li><p>Rate of convergence of pre-smoothing is a power of <span class="math inline">\(1/N\)</span> (power of, say, <span class="math inline">\(2/5\)</span> if <span class="math inline">\(2\)</span> derivatives are assumed to exist, etc.) so we need a power that is a polynomial larger than <span class="math inline">\(1/N\)</span> which is achieved by an exponential -log() with a power that is smaller than 1 (explains why <span class="math inline">\(\Delta_*\)</span> is of this form) should be going to zero slower than any polynomial 1/N</p></li>
<li><p><span class="math inline">\(\Delta_*\)</span> should be negligible with respect to rate of convergence with respect to <span class="math inline">\(h\)</span></p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="estimation" class="slide level2 center">
<h2>Estimation</h2>
<ul>
<li class="fragment"><p>The idea is to estimate <span class="math inline">\(\theta(t_1,t_3)\)</span> and <span class="math inline">\(\theta(t_1,t_2)\)</span> <em>averaging vertically</em> over curves</p></li>
<li class="fragment"><p>Given estimates <span class="math inline">\(\widehat\theta(t_1,t_3)\)</span> and <span class="math inline">\(\widehat\theta(t_1,t_2)\)</span>, the estimators of <span class="math inline">\(H_{t}\)</span> and <span class="math inline">\(L_t\)</span> are given by <span class="math display">\[\begin{equation*}
\widehat H_t =  \frac{\log(\widehat\theta(t_1,t_3)) - \log(\widehat\theta(t_1,t_2))}{2\log(2)},\quad
\widehat L_t = \frac{\sqrt{\widehat\theta(t_1,t_3)}}{|t_1-t_3|^{\widehat H_t} }
\end{equation*}\]</span></p></li>
<li class="fragment"><p>The estimator <span class="math inline">\(\widehat{\theta}(t_l,t_j)\)</span> is the average of local curve smoothers, i.e., <span class="math display">\[\begin{equation*}
\widehat{\theta}(t_l,t_j)=\frac{1}{N}\sum_{i = 1}^N\left(\widetilde X^{(i)}(t_l)-\widetilde X^{(i)}(t_j)\right)^2
\end{equation*}\]</span></p></li>
<li class="fragment"><p>The smoother <span class="math inline">\(\widetilde X^{(i)}(t)\)</span> depends on a bandwidth <span class="math inline">\(h_t\)</span> that, post-iteration, adapts to the local regularity of the underlying process</p></li>
</ul>
<!--

##  Nonparametric Smoother

-   To construct $\widehat H_t$ and $\widehat L_t$ on the previous slide, we use a generic kernel-based smoother on *de-meaned* $Y^{(i)}_m$ given by \begin{equation*}
    \widetilde X^{(i)}(t) = \sum_{m=1}^{M_i} W_{m}^{(i)}(t;h_t) \left(Y^{(i)}_m -\widetilde\mu(T^{(i)}_m)\right),\, \sum_{m=1}^{M_i}W_{m}^{(i)}(t;h_t) =1
    \end{equation*}

-   The weights $W_{m}^{(i)}(t;h_t)$ are functions of the elements in $\mathcal T_{obs}^{(i)} = \left\{ T_1^{(i)},\ldots, T_{M_i}^{(i)}\right\}$, and depend on a bandwidth $h_t$ which can vary with $t$

-   The main case we have in mind is local polynomial smoothing

-   In the case of non-differentiable functions (our main focus lies here), we consider the local constant NW estimator [@nadaraya:1965; @watson:1964]

##  Nonparametric Smoother

-   The weights of the NW estimator of $X^{(i)}(t)$ are \begin{equation*}
    W_{m}^{(i)}(t;h_t)  = K\left( \frac{T^{(i)}_m-t}{h_t} \right)\left[\sum_{m'=1}^{M_i} K\left( \frac{T^{(i)}_{m'}-t}{h_t} \right)\right]^{-1},
    \quad 1\leq m \leq M_i
    \end{equation*}

-   $K(u)$ is a symmetric, non-negative, bounded kernel with support in $[-1,1]$ [e.g., @epanechnikov:1969]

-   For estimating $\mu(t)$ and $\Gamma(s,t)$ we might entertain an indicator associated with the weights $W_{m}^{(i)}(t;h)$, that is \begin{equation*}
    w^{(i)}(t;h) = 1 \quad \text{if} \quad \sum_{i=1}^{M_i} \mathbf 1 \left\{\left|T^{(i)}_m-t\right|\leq h\right\} >1, \quad \text{and } 0 \text{ otherwise}
    \end{equation*}

-   When $w^{(i)}(t;h) = 0$ we *discard* the $i$th curve *vertically* as we lack information local to $t$ (i.e., if all $W_{m}^{(i)}(t;h)=0$, where $0/0\coloneqq0$)

-->
</section></section>
<section>
<section id="assumptions" class="title-slide slide level1 center">
<h1>Assumptions</h1>

</section>
<section id="assumptions-1" class="slide level2 center">
<h2>Assumptions</h2>
<ul>
<li class="fragment"><p>The stochastic process <span class="math inline">\(X\)</span> is a random function taking values in <span class="math inline">\(L^2 (\mathcal T)\)</span>, with <span class="math inline">\(\mathbb E (\| X\|^2) &lt;\infty\)</span></p></li>
<li class="fragment"><p>The process is <em>not</em> deterministic with all sample paths equal to a common path</p></li>
<li class="fragment"><p>The increments of the process have any moment, and the distributions of the increments are sub-Gaussian</p></li>
<li class="fragment"><p>The functions <span class="math inline">\(X^{(i)}(t)\)</span> may be nowhere differentiable</p></li>
<li class="fragment"><p>The process <span class="math inline">\(X\)</span> may be non-stationary with non-stationary increments</p></li>
<li class="fragment"><p>The measurement errors <span class="math inline">\(\varepsilon^{(i)}\)</span> may be heteroscedastic</p></li>
<li class="fragment"><p>The mean function <span class="math inline">\(\mu(t)\)</span> may be smoother than the <span class="math inline">\(X^{(i)}(t)\)</span> functions</p></li>
<li class="fragment"><p><span class="math inline">\(0&lt;L_t&lt;\infty\)</span> and <span class="math inline">\(0&lt;H_t&lt;1\)</span></p></li>
</ul>
<aside class="notes">
<ul>
<li>In probability theory, a sub-Gaussian distribution is a probability distribution with strong tail decay. Informally, the tails of a sub-Gaussian distribution are dominated by (i.e.&nbsp;decay at least as fast as) the tails of a Gaussian</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="estimation-of-local-regularity" class="title-slide slide level1 center">
<h1>Estimation of Local Regularity</h1>

</section>
<section id="methodology" class="slide level2 center">
<h2>Methodology</h2>
<ul>
<li class="fragment"><p>We take the optimal bandwidth expression for <span class="math inline">\(h_t\)</span> (which depends on <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span>) that minimizes <em>pointwise</em> MSE using a <em>general</em> squared bias term (not the usual term one gets assuming twice differentiable curves)</p></li>
<li class="fragment"><p>Then, given an initial batch of <span class="math inline">\(N\)</span> curves, we estimate <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> for each <span class="math inline">\(t\in \mathcal T_0\)</span>, which involves an <em>iterative plug-in</em> procedure:</p>
<ol type="1">
<li class="fragment"><p>begin with some starting values for the local bandwidths <span class="math inline">\(h_t\)</span></p></li>
<li class="fragment"><p>construct preliminary estimates of each curve for every <span class="math inline">\(t\in \mathcal T_0\)</span> using the data pairs <span class="math inline">\((Y^{(i)}_m , T^{(i)}_m)\)</span> and local bandwidth starting values</p></li>
<li class="fragment"><p>use these preliminary curve estimates to get starting values for <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> for every <span class="math inline">\(t\in \mathcal T_0\)</span>, and plug these into the optimal bandwidth expression</p></li>
<li class="fragment"><p>repeat 1-3 using the updated plug-in bandwidths; continue iterating <span class="math inline">\(H_T\)</span>, and <span class="math inline">\(L_t\)</span> and <span class="math inline">\(h_t\)</span> for every <span class="math inline">\(t\in \mathcal T_0\)</span> until the procedure stabilizes (this occurs quite quickly, typically after 10 or so iterations)</p></li>
</ol></li>
</ul>
</section>
<section id="details" class="slide level2 center">
<h2>Details</h2>
<ul>
<li class="fragment"><p>To estimate the <span class="math inline">\(i\)</span>th curve at a point <span class="math inline">\(t\)</span> with local Hölder exponent <span class="math inline">\(H_t\)</span> and local Hölder constant <span class="math inline">\(L_t\)</span>, the MSE-optimal bandwidth <span class="math inline">\(h^*_{t,HL}\)</span> is <span class="math display">\[\begin{equation*}
h^*_{t,HL} =  \left[ \frac{\sigma_t^2 \int K^2(u)du }{2H_t L_t^2\times  \int |u|^{2H_t}|K(u)|du\times f_T(t)}\times \frac{1}{\bar M_i} \right]^{\frac{1}{2H_t+1}}
\end{equation*}\]</span></p></li>
<li class="fragment"><p>The kernel function <span class="math inline">\(K(u)\)</span> is provided by the user hence <span class="math inline">\(\int K^2(u)du\)</span> and <span class="math inline">\(\int |u|^{2H_t}|K(u)|du\)</span> can be computed given <span class="math inline">\(H_t\)</span></p></li>
<li class="fragment"><p><span class="math inline">\(\sigma_t^2\)</span> is estimated using one-half the squared differences of the two closest <span class="math inline">\(Y^{(i)}\)</span> observations at <span class="math inline">\(t\)</span>, averaged across all curves</p></li>
<li class="fragment"><p>The design density <span class="math inline">\(f_T(t)\)</span> is straightforward to estimate</p></li>
<li class="fragment"><p>We estimate <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> for some batch of <span class="math inline">\(N\)</span> curves as outlined on the previous slide, then we recursively update them as online data arrives</p></li>
</ul>
</section>
<section id="mfbm-example-independent-design" class="slide level2 center">
<h2>MfBm Example (independent design)</h2>

<img data-src="index_files/figure-revealjs/fig-mfbmcurves-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;7: Multifractional Brownian Motion - True Curves
</p></section>
<section id="mfbm-example-independent-design-1" class="slide level2 center">
<h2>MfBm Example (independent design)</h2>

<img data-src="index_files/figure-revealjs/fig-mfbmdata-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;8: Multifractional Brownian Motion - Data
</p></section>
<section id="mfbm-example-independent-design-2" class="slide level2 center">
<h2>MfBm Example (independent design)</h2>

<!--

## MfBm Example (independent design)


::: {.cell layout-align="center"}
::: {.cell-output-display}
![Multifractional Brownian Motion - Local Hölder Exponents Iteration](index_files/figure-revealjs/fig-mfbmiterH-1.png){#fig-mfbmiterH fig-align='center' width=960}
:::
:::


-->
<img data-src="index_files/figure-revealjs/fig-mfbmiterhHL-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;9: Multifractional Brownian Motion - Bandwidth Iteration
</p></section>
<section id="mfbm-example-independent-design-3" class="slide level2 center">
<h2>MfBm Example (independent design)</h2>

<img data-src="index_files/figure-revealjs/fig-mfbmHtrue-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;10: Multifractional Brownian Motion - Estimated and True Regularity
</p></section>
<section id="berkeley-growth-study-example-common-design" class="slide level2 center">
<h2>Berkeley Growth Study Example (common design)</h2>

<img data-src="index_files/figure-revealjs/fig-growthH-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;11: Berkeley Growth Example - Estimated Regularity
</p></section>
<section id="canadian-weather-study-example-common-design" class="slide level2 center">
<h2>Canadian Weather Study Example (common design)</h2>

<img data-src="index_files/figure-revealjs/fig-canWeatherH-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;12: Canadian Weather Example - Estimated Regularity
</p></section>
<section id="h_t-comparison-growth-canweather-mfbm" class="slide level2 center">
<h2><span class="math inline">\(H_t\)</span> Comparison: growth, canWeather, MfBm</h2>

<img data-src="index_files/figure-revealjs/fig-boxplotH-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;13: Estimated Regularity Comparison
</p></section></section>
<section>
<section id="estimation-of-mut-and-gammast" class="title-slide slide level1 center">
<h1>Estimation of <span class="math inline">\(\mu(t)\)</span> and <span class="math inline">\(\Gamma(s,t)\)</span></h1>

</section>
<section id="estimation-of-mut-and-gammast-1" class="slide level2 center">
<h2>Estimation of <span class="math inline">\(\mu(t)\)</span> and <span class="math inline">\(\Gamma(s,t)\)</span></h2>
<ul>
<li class="fragment"><p>In order to estimate <span class="math inline">\(\mu(t)\)</span> at point <span class="math inline">\(t\)</span> and <span class="math inline">\(\Gamma(s,t)\)</span> at points <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span>, ideally we would use the (unknown, continuous) curves evaluated at these points, hence the <em>ideal</em> estimators given <span class="math inline">\(N\)</span> curves would be <span class="math display">\[\begin{align*}
\widehat \mu(t)&amp;=\frac{1}{N}\sum_{i=1}^N X^{(i)}(t)\\
\widehat \Gamma(s,t)&amp;=\frac{1}{N}\sum_{i=1}^N \left(X^{(i)}(s)-\mu(s)\right)\left(X^{(i)}(t)-\mu(t)\right)
\end{align*}\]</span></p></li>
<li class="fragment"><p>Of course, these are <em>infeasible</em> as we don’t observe the true curves, we observe <span class="math inline">\(M_i\)</span> noisy sample pairs for each curve <span class="math inline">\(X^{(i)}\)</span> measured at <em>random</em> points</p></li>
<li class="fragment"><p>That is, we observe <span class="math inline">\(Y^{(i)}_m=X^{(i)}(T_m^{(i)})+\varepsilon^{(i)}_m\)</span> at discrete irregularly spaced <span class="math inline">\(T_m^{(i)}\)</span>, i.e., we observe vectors of pairs <span class="math inline">\((Y^{(i)}_m,T_m^{(i)})\)</span> of length <span class="math inline">\(M_i\)</span>, <span class="math inline">\(i=1,\dots,N\)</span></p></li>
</ul>
</section>
<section id="estimation-of-mut-and-gammast-cont." class="slide level2 center">
<h2>Estimation of <span class="math inline">\(\mu(t)\)</span> and <span class="math inline">\(\Gamma(s,t)\)</span> Cont.</h2>
<ul>
<li class="fragment"><p>Our estimates of <span class="math inline">\(\mu(t)\)</span> and <span class="math inline">\(\Gamma(s,t)\)</span>, like those of <span class="math inline">\(X^{(i)}\)</span>, are local in nature and adapt to <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span></p></li>
<li class="fragment"><p>It can be shown that to estimate <span class="math inline">\(\mu(t)\)</span> and <span class="math inline">\(\Gamma(s,t)\)</span> at points <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span> with local Hölder exponent <span class="math inline">\(H_t\)</span> and local Hölder constant <span class="math inline">\(L_t\)</span>, the MSE-optimal bandwidths are given by <span class="math display">\[\begin{align*}
h^*_{t,\mu} &amp;=  \left[ \frac{\sigma_t^2 \int K^2(u)du }{2H_t L_t^2\times  \int |u|^{2H_t}|K(u)|du\times f_T(t)}\times \frac{1}{N\bar M_i} \right]^{\frac{1}{2H_t+1}},\\
h^*_{t,\Gamma} &amp;=  \left[ \frac{\sigma_t^2 \int K^2(u)du }{4H_t L_t^2\times  \int |u|^{2H_t}|K(u)|du\times f_T(t)}\times \frac{1}{N\bar M^2_i} \right]^{\frac{1}{2H_t+2}}
%% Note this is the "sparse" Gamma bandwidth when N exceeds M (don't want to clutter with min of 2 bandwidths)
\end{align*}\]</span></p></li>
<li class="fragment"><p>Using estimates of <span class="math inline">\(H_t\)</span>, <span class="math inline">\(L_t\)</span>, <span class="math inline">\(\sigma_t\)</span> and <span class="math inline">\(f_T(t)\)</span> from the batch of <span class="math inline">\(N\)</span> curves, we smooth <span class="math inline">\(X^{(i)}(s)\)</span> and <span class="math inline">\(X^{(i)}(t)\)</span> using <span class="math inline">\(\widehat h_{t,\mu}\)</span> and <span class="math inline">\(\widehat h_{t,\Gamma}\)</span> to construct <span class="math inline">\(\widehat\mu(t)\)</span> and <span class="math inline">\(\widehat\Gamma(s,t)\)</span> (here we use, e.g., <span class="math inline">\(\widehat X^{(i)}(t) = \sum_{m=1}^{M_i} W_{m}^{(i)}(t;\widehat h_{t,\Gamma}) Y^{(i)}_m\)</span>)</p></li>
</ul>
</section>
<section id="example-estimation-of-gammast" class="slide level2 center">
<h2>Example: Estimation of <span class="math inline">\(\Gamma(s,t)\)</span></h2>

<img data-src="index_files/figure-revealjs/fig-growthgamma-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;14: Berkeley Growth
</p></section>
<section id="example-estimation-of-gammast-1" class="slide level2 center">
<h2>Example: Estimation of <span class="math inline">\(\Gamma(s,t)\)</span></h2>

<!--

## Example: Estimation of $\Gamma(s,t)$


::: {.cell layout-align="center"}
::: {.cell-output-display}
![Multifractional Brownian Motion](index_files/figure-revealjs/fig-mfbmgamma-1.png){#fig-mfbmgamma fig-align='center' width=960}
:::
:::


-->
<!--

# Curve Recovery

## Curve Recovery

-   Sometimes one needs to estimate a curve, e.g., a new online sample arrives and one is interested in estimating the (unknown) new online curve at some point $t_0\in[0,1]$

-   We wish to build an estimator of $X^{(i)}(t_0)$ making use of information in the noisy measurements $(Y^{(i)}_m,T^{(i)}_m)$ of $X^{(i)}$, and can do so by exploiting information provided by the mean and covariance functions of the process $X$

-   Recall that $\mathcal{T}^{(i)}$ represents the set of design points where the curve $X^{(i)}$ is measured with error ($t_0$ can be an element of $\mathcal{T}^{(i)}$, or not)

-   Let $\mathbb{Y}^{(i)}=(\mathbb{Y}^{(i)}_1,\dots,\mathbb{Y}^{(i)}_{M_i})^T$, and $\mathbb{X}^{(i)}=(\mathbb{X}^{(i)}(T^{(i)}_1),\dots,\mathbb{X}^{(i)}(T^{(i)}_{M_i}))^T$

## Curve Recovery Cont.

-   We use the following vectors and matrices determined by the mean and covariance structure of $X$ and the noise variance: \begin{align*}
    \mu^{(i)}=\left(\mu(T^{(i)}_m)\right)_{1\le m\le M_i},&\qquad
    \Gamma^{(i)}=\left(\Gamma(T^{(i)}_m,T^{(i)}_{m'})\right)_{1\le m,m'\le M_i},\\\text{and}\quad
    \Sigma^{(i)}&=\text{diag}\left(\sigma^2(T^{(i)}_m)\right)_{1\le m\le M_i}
    \end{align*}

-   The type of prediction we consider has the form ($\widetilde X_{inf}^{(i)}(t_0)$ is infeasible) \begin{equation*}
    \widetilde X_{inf}^{(i)}(t_0)=\mu(t_0)+\beta_{t_0}^T\left\{\mathbb{Y}^{(i)}-\mu^{(i)}\right\}
    \end{equation*}

-   Here, $\beta_{t_0}$ is theoretical quantity which depends on unknown quantities, but a feasible version can be readily constructed by noting that \begin{equation*}
    \beta_{t_0}=\operatorname{Var}^{-1}_{M,T}\left(\mathbb{Y}^{(i)}\right)\operatorname{Cov}_{M,T}\left(\mathbb{Y}^{(i)},X^{(i)}(t_0)\right)
    \end{equation*}

## Curve Recovery Cont.

-   It can be shown that \begin{equation*}
    \beta_{t_0}=\left(\Gamma^{(i)}+\Sigma^{(i)}\right)^{-1}\Gamma^{(i)}_{t_0}
    \end{equation*}

-   Of course, this estimator is infeasible, but given *existing* estimates of $h$, $H$, $L$, $\mu$, $\Gamma$ and $\sigma$, we have a feasible estimator given by \begin{equation*}
    \widetilde X^{(i)}(t_0)=\widehat\mu(t_0)+\widehat\beta_{t_0}^T\left\{\mathbb{Y}^{(i)}-\widehat\mu^{(i)}\right\}\text{ where } \widehat\beta_{t_0}=\left(\widehat\Gamma^{(i)}+\widehat\Sigma^{(i)}\right)^{-1} \widehat\Gamma^{(i)}_{t_0}
    \end{equation*}

-   We expect (and simulations underscore) that this estimator is capable of outperforming the individual *local* curve estimates used to construct $H_t$ and $L_t$ in some settings given a sufficient number of curves (i.e., the $\widehat X^{(i)}(t)$ considered previously)

-   We also propose a "combined" estimator that is a *data-driven convex combination* of the reconstructed estimator $\widetilde X^{(i)}(t_0)$ and the individual curve estimator $\widehat X^{(i)}(t_0)$

## Example: Curve Recovery Versus Smooth Estimation


::: {.cell layout-align="center"}
::: {.cell-output-display}
![MfBm Curve Reconstruction](index_files/figure-revealjs/fig-Brownianrecon-1.png){#fig-Brownianrecon fig-align='center' width=960}
:::
:::


-->
<img data-src="index_files/figure-revealjs/fig-canweathergamma-1.png" class="quarto-figure quarto-figure-center r-stretch" width="960"><p class="caption">
Figure&nbsp;15: Canadian Weather
</p></section></section>
<section>
<section id="online-recursive-updating" class="title-slide slide level1 center">
<h1>Online Recursive Updating</h1>
<!--

## Online Recursive Updating

-   As $N$ increases batch computation can become infeasible

-   Furthermore, new online curves may arrive in real-time

-   We may need to update our batch estimates in real-time, i.e., our estimates of $H_t$, $L_t$, $h_{t,HL}$, $h_{t,\mu}$, $h_{t,\Gamma}$, $\mu(t)$, $\sigma(t)$, $f_T(t)$, and $\Gamma(s,t)$

-   We shall rely on recursive methods, i.e., "stochastic approximation" algorithms, which date to @robbins_munro:1951 and @kiefer_wolfowitz:1952

-   The challenge is a) to avoid batch computation when the number of curves gets unmanageably large, and b) to process online curves in real-time with negligible memory and computational overhead

-   Though recursive updating will necessarily be sub-optimal, if done properly the efficiency loss will be negligible and can be controlled (batch computation on all curves would be optimal but infeasible)

-->
</section>
<section id="online-recursive-updating-of-local-hölder-exponent" class="slide level2 center">
<h2>Online Recursive Updating of Local Hölder Exponent</h2>
<ul>
<li class="fragment"><p>Given observations from a new online curve <span class="math inline">\(X^{(i+1)}\)</span>, let the local bandwidth <span class="math inline">\(\widehat h_{t,HL}\)</span> be that based on the estimates of <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> for recursion <span class="math inline">\(i\)</span> (call this <span class="math inline">\(\widehat h_{t,HL}^{(i)}\)</span>)</p></li>
<li class="fragment"><p>Let <span class="math inline">\(\gamma_{i+1}=(\sum_{j=1}^iM_j)/(\sum_{j=1}^iM_j+M_{i+1})\)</span> (which equals <span class="math inline">\(i/(i+1)\)</span> if <span class="math inline">\(M_1=\dots=M_{i+1}\)</span>), and let <span class="math inline">\(\widehat{\theta}_i(u,v)=\frac{1}{i}\sum_{j = 1}^i\left\{\widehat X^{(j)}(u)-\widehat X^{(j)}(v)\right\}^2\)</span></p></li>
<li class="fragment"><p>The recursively updated estimator of <span class="math inline">\(\theta(u,v)\)</span> using <span class="math inline">\(\widehat h_{t,HL}^{(i)}\)</span> is given by <span class="math display">\[\begin{equation*}
  \widehat\theta_{i+1}(u,v) = \gamma_{i+1} \widehat\theta_{i}(u,v)+ (1-\gamma_{i+1}) \left\{\widehat{X}^{(i+1)}(u) - \widehat{X}^{(i+1)}(v)\right\}^2
\end{equation*}\]</span></p></li>
<li class="fragment"><p>The recursively updated estimators of <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> are then obtained via <span class="math display">\[\begin{equation*}
  \widehat H_{t,i+1} = \frac{\log\big( \widehat\theta_{i+1}(t_1,t_3)\big) - \log \big(\widehat\theta_{i+1}(t_1,t_2)\big)}{2\log (2)},\quad\widehat L_{t,i+1} = \frac{\sqrt{\widehat\theta_{i+1}(t_1,t_3)}}{|t_1-t_3|^{\widehat H_{t,i+1}}}
\end{equation*}\]</span></p></li>
</ul>
</section>
<section id="online-recursive-updating-of-local-hölder-exponent-1" class="slide level2 center">
<h2>Online Recursive Updating of Local Hölder Exponent</h2>
<ul>
<li class="fragment"><p>Updated estimators of <span class="math inline">\(\sigma(t)\)</span> and <span class="math inline">\(f_T(t)\)</span> are recursively computable</p></li>
<li class="fragment"><p>The recursively updated estimators of <span class="math inline">\(h_{t,HL}\)</span>, <span class="math inline">\(h_{t,\mu}\)</span>, <span class="math inline">\(h_{t,\Gamma}\)</span> can then be computed (recall they depend on <span class="math inline">\(H_t\)</span>, <span class="math inline">\(L_t\)</span>, <span class="math inline">\(\sigma(t)\)</span>, and <span class="math inline">\(f_T(t)\)</span>), and call these <span class="math inline">\(\widehat h_{t,HL}^{(i+1)}\)</span>, <span class="math inline">\(\widehat h_{t,\mu}^{(i+1)}\)</span>, and <span class="math inline">\(\widehat h_{t,\Gamma}^{(i+1)}\)</span></p></li>
<li class="fragment"><p>Using <span class="math inline">\(\widehat h_{t,\mu}^{(i+1)}\)</span> or <span class="math inline">\(\widehat h_{t,\Gamma}^{(i+1)}\)</span> we can estimate <span class="math inline">\(X^{(i+1)}(t)\)</span> and recursively update the estimators of <span class="math inline">\(\mu(t)\)</span> or <span class="math inline">\(\Gamma(s,t)\)</span>, again using <span class="math inline">\(\gamma_{i+1}\)</span> and <span class="citation" data-cites="robbins_munro:1951">Robbins and Monro (<a href="#/references-scrollable" role="doc-biblioref" onclick="">1951</a>)</span> (<span class="math inline">\(\widehat h_{t,HL}^{(i+1)}\)</span> will start the next recursion for <span class="math inline">\(X^{(i+2)}(t)\)</span>, etc.)</p></li>
<li class="fragment"><p>The “memory footprint” is determined by the grid <span class="math inline">\(\mathcal T_0\subset [0,1]\)</span> (e.g., 100 equidistant points) since we construct estimates of <span class="math inline">\(\mu(\cdot)\)</span>, <span class="math inline">\(\sigma(\cdot)\)</span>, <span class="math inline">\(f_T(\cdot)\)</span> on <span class="math inline">\(\mathcal T_0\)</span> and estimates of <span class="math inline">\(\Gamma(\cdot,\cdot)\)</span> on <span class="math inline">\(\mathcal T_0 \times \mathcal T_0\)</span></p></li>
<li class="fragment"><p>Thus, our procedures require only that we retain and update vectors and matrices of length <span class="math inline">\(\mathcal T_0\)</span> and dimension <span class="math inline">\(\mathcal T_0 \times \mathcal T_0\)</span></p></li>
</ul>
</section>
<section id="online-recursive-updating-clip" class="slide level2 center">
<h2>Online Recursive Updating Clip</h2>
<video id="video_shortcode_videojs_video1" width="640" height="640" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="R_scripts_data/movie.mov"></video>
<!--

## Recursive Updating: Finite-Sample Performance

::: {.panel-tabset}

## Varying $M$, $N=16000$

@tbl-rmseMtable summarizes RMSE performance for 1,000 Monte Carlo replications from a multifractional Brownian motion with covariance $\Gamma(s,t)$ based on $\tau=1$, $L_t=1$, $H_t\in[0.25,0.75]$, $\sigma=0.25$, with $\mu(t)=\sin(2\pi t)$, $t\sim U[0,1]$, *independent design* with $M_i=M$, $N=16000$ online curves, an initial batch of $N=5$ curves to "burn in" values for $H_t$ and $L_t$, and a grid of 100 equidistant points for $\mathcal T_0\in[0,1]$


::: {#tbl-rmseMtable .cell layout-align="center" tbl-cap='Mean RMSE after final recursion'}
::: {.cell-output-display}


| $M$ | $\widehat h_{H_t,L_t}$ | $\widehat H_t$ | $\widehat X^{(i)}$ | $\widehat\mu(t)$ | $\widehat\Gamma(s,t)$ |
|:---:|:----------------------:|:--------------:|:------------------:|:----------------:|:---------------------:|
| 100 |         0.0108         |     0.1479     |       0.1899       |      0.0202      |        0.0495         |
| 200 |         0.0076         |     0.1395     |       0.1622       |      0.0186      |        0.0425         |
| 400 |         0.0051         |     0.1172     |       0.1384       |      0.0167      |        0.0360         |
| 800 |         0.0032         |     0.0860     |       0.1185       |      0.0149      |        0.0309         |


:::
:::


## Varying $N$, $M=200$

@tbl-rmseM200Ntable summarizes the finite sample RMSE performance of two $\Gamma(s,t)$ estimators that either a) discard degenerate points vertically ("skip") or b) use the recovered curves based on the previous estimate of $\Gamma(s,t)$ ("lp"), as the number of online curves processed increases from $N=1000,2000,...,16000$, $M=200$


::: {#tbl-rmseM200Ntable .cell layout-align="center" tbl-cap='Mean RMSE after final recursion'}
::: {.cell-output-display}


|  $N$  | $\widehat\Gamma(s,t)_{\text{skip}}$ | $\widehat\Gamma(s,t)_{\text{lp}}$ |
|:-----:|:-----------------------------------:|:---------------------------------:|
| 1000  |               0.1006                |              0.0596               |
| 2000  |               0.0799                |              0.0416               |
| 4000  |               0.0642                |              0.0297               |
| 8000  |               0.0524                |              0.0216               |
| 16000 |               0.0425                |              0.0152               |


:::
:::


:::

-->
</section></section>
<section>
<section id="summary-and-appendices" class="title-slide slide level1 center">
<h1>Summary and Appendices</h1>

</section>
<section id="summary" class="slide level2 center">
<h2>Summary</h2>
<ul>
<li class="fragment"><p>Though this project has a lot of moving parts, we demonstrate that the approach can deliver consistent computationally feasible FDA</p></li>
<li class="fragment"><p>Most importantly, our method is <em>data-driven</em> and <em>locally adaptive</em> to the regularity of the stochastic process</p></li>
<li class="fragment"><p>We support both batch estimation and online updating using computationally attractive approaches</p></li>
<li class="fragment"><p>Though not mentioned explicitly so far, the pointwise asymptotics for the individual curve, mean curve, and covariance curve estimates are established and can be used to construct interval estimates etc.</p></li>
<li class="fragment"><p>R code exists and we expect to be releasing this publicly in the near future</p></li>
</ul>
</section>
<section id="appendix-a-resources" class="slide level2 center">
<h2>Appendix A: Resources</h2>
<ul>
<li class="fragment"><p>Books:</p>
<ul>
<li class="fragment"><span class="citation" data-cites="ramsay_silverman:2005">Ramsay and Silverman (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2005</a>)</span>, <span class="citation" data-cites="horvath_kokoszka:2012">Horváth and Kokoszka (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2012</a>)</span>, <span class="citation" data-cites="kokoszka_reimherr:2017">Kokoszka and Reimherr (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2017</a>)</span></li>
</ul></li>
<li class="fragment"><p>Review Articles:</p>
<ul>
<li class="fragment"><span class="citation" data-cites="wang_chiou_muller:2016">Wang, Chiou, and Müller (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2016</a>)</span>, <span class="citation" data-cites="reiss_et_al:2017">Reiss et al. (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2017</a>)</span></li>
</ul></li>
<li class="fragment"><p>R packages:</p>
<ul>
<li class="fragment">fda <span class="citation" data-cites="fda">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Ramsay, Graves, and Hooker 2022</a>)</span>, fdapace <span class="citation" data-cites="fdapace">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Zhou et al. 2022</a>)</span>, fda.usc <span class="citation" data-cites="fda.usc">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Febrero-Bande and Oviedo de la Fuente 2012</a>)</span></li>
</ul></li>
<li class="fragment"><p>FDA CRAN Task View:</p>
<ul>
<li class="fragment"><a href="https://cran.r-project.org/view=FunctionalData" class="uri">https://cran.r-project.org/view=FunctionalData</a></li>
</ul></li>
<li class="fragment"><p>Applications in Economics:</p>
<ul>
<li class="fragment"><span class="citation" data-cites="padilla_segarra_et_al:2020">Padilla-Segarra et al. (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2020</a>)</span>, <span class="citation" data-cites="tian_renfang:2020">Tian, Renfang (<a href="#/references-scrollable" role="doc-biblioref" onclick="">2020</a>)</span></li>
</ul></li>
</ul>
</section>
<section id="appendix-b-mfbm-gaussian-processes" class="slide level2 center">
<h2>Appendix B: MfBm Gaussian Processes</h2>
<ul>
<li class="fragment"><p>A Multifractional Brownian Motion <span class="citation" data-cites="peltier_vehel:1995">(MfBm, <a href="#/references-scrollable" role="doc-biblioref" onclick="">Peltier and Lévy Véhel 1995</a>)</span>, say <span class="math inline">\((W(t))_{t\geq 0}\)</span>, with Hurst index function <span class="math inline">\(H_t \in(0,1)\)</span>, is a centred Gaussian process with covariance function <span class="math display">\[\begin{equation*}
C(s,t) = \mathbb{E}\left[W(s)W(t)\right] =  D(H_s,H_t )\left[ s^{H_s+H_t} +  t^{H_s+H_t} - |t-s|^{H_s+H_t}\right],\, s, t\geq 0,
\end{equation*}\]</span> where <span class="math display">\[\begin{equation*}
D(x,y)=\frac{\sqrt{\Gamma (2x+1)\Gamma (2y+1)\sin(\pi x)\sin(\pi y)}} {2\Gamma (x+y+1)\sin(\pi(x+y)/2)}, \, D(x,x) = 1/2,\, x,y &gt;0
\end{equation*}\]</span></p></li>
<li class="fragment"><p>Define the Hurst index function given <span class="math inline">\(0 &lt;\underline H \leq \overline H &lt;1\)</span>, a change point <span class="math inline">\(t_c \in (0,1)\)</span>, and a slope <span class="math inline">\(S&gt;0\)</span>, by <span class="math display">\[\begin{equation*}
H_t = \underline H + \frac{\overline H - \underline H}{1+\exp(- S (t-t_c))}, \qquad t\in [0,1]
\end{equation*}\]</span></p></li>
</ul>
</section>
<section id="appendix-b-mfbm-gaussian-processes-cont." class="slide level2 center">
<h2>Appendix B: MfBm Gaussian Processes Cont.</h2>
<ul>
<li class="fragment"><p>The MfBm data are then generated as follows <span class="citation" data-cites="chan_wood:1998">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Chan and Wood 1998</a>)</span></p>
<ul>
<li class="fragment"><p>for each <span class="math inline">\(i\)</span>, an integer <span class="math inline">\(M_i\)</span> is generated as a realization of some random variable with mean <span class="math inline">\(\mathfrak m\)</span> (e.g., Poisson), or <span class="math inline">\(M_i\)</span> could be a constant</p></li>
<li class="fragment"><p>next, generate <span class="math inline">\(M_i\)</span> independent draws <span class="math inline">\(T_1^{(i)},\ldots,T_{M_i}^{(i)}\)</span> from a uniform random variable on <span class="math inline">\([0,1]\)</span></p></li>
<li class="fragment"><p>using the covariance formula above, the <span class="math inline">\(M_i\times M_i\)</span> matrix <span class="math inline">\(C^{(i)}\)</span> with the entries <span class="math display">\[\begin{equation*}
C^{(i)}(T_m^{(i)}, T_{m^\prime}^{(i)}),\quad 1\leq m,m^\prime \leq M_i,
\end{equation*}\]</span> is computed</p></li>
</ul></li>
<li class="fragment"><p>The <span class="math inline">\(M_i\)</span>-dimensional vector with components <span class="math inline">\(X^{(i)}(T_n^{(i)})\)</span>, <span class="math inline">\(1\leq m \leq M_i\)</span> is the realization of a zero mean Gaussian distribution with covariance matrix <span class="math inline">\(C^{(i)}\)</span></p></li>
<li class="fragment"><p>While the <em>increments</em> for Brownian Motion (i.e., when <span class="math inline">\(H_t=1/2\)</span>) are stationary and independent, increments for MfBm are neither</p></li>
</ul>
</section>
<section id="appendix-c-non-smooth-irregular" class="slide level2 center">
<h2>Appendix C: (Non-)Smooth, (Ir)Regular</h2>
<ul>
<li class="fragment"><p>We use the terms “smooth” and “regular”, or their opposites “non-smooth” and “irregular” so we provide some background that might be helpful</p></li>
<li class="fragment"><p>We use “smoothness” of a function in the standard sense, i.e.,</p>
<ul>
<li class="fragment"><p>smoothness is measured by the number of continuous derivatives over some domain (called the “differentiability class”)</p></li>
<li class="fragment"><p>at minimum, a function is considered smooth if it is “differentiable everywhere” (hence continuous)</p></li>
<li class="fragment"><p>at the other extreme, if it also possesses continuous derivatives of all orders it is said to be “infinitely differentiable” and is often referred to as a “<span class="math inline">\(C^{{\infty }}\)</span> function”</p></li>
</ul></li>
<li class="fragment"><p>Thus, “non-smooth” functions are not differentiable everywhere, and in the extreme may be “nowhere differentiable”</p></li>
</ul>
</section>
<section id="appendix-c-non-smooth-irregular-cont." class="slide level2 center">
<h2>Appendix C: (Non-)Smooth, (Ir)Regular Cont.</h2>
<ul>
<li class="fragment"><p>We use the term “irregular” to refer to non-smooth functions whose “Hölder continuity exponent” varies over some domain</p></li>
<li class="fragment"><p>We have in mind Hölder continuity where the “Hölder exponent” <span class="math inline">\(H\)</span> defines the regularity of the function (also called its “Hurst” index)</p></li>
<li class="fragment"><p>But, in addition, we have in mind that such regularity might vary over <span class="math inline">\(t\)</span> hence we write <span class="math inline">\(H_t\)</span> and call this the “local Hölder exponent”</p></li>
<li class="fragment"><p>The Hölder continuity condition you may be familiar with is <span class="math display">\[|X_u-X_v|\le L|u-v|^H,\quad 0&lt;L&lt;\infty,\quad 0&lt;H&lt; 1\]</span></p></li>
<li class="fragment"><p>So taking the square we have <span class="math display">\[|X_u-X_v|^2\le L^2|u-v|^{2H}\]</span></p></li>
</ul>
<aside class="notes">
<ul>
<li><p>Roughly speaking, one can think of Hölder continuous functions with exponent α as functions with bounded fractional derivatives of the the order α</p></li>
<li><p>There is no purpose in considering Hölder continuous functions with exponent greater than one, since any such function is differentiable with zero derivative and therefore is constant</p></li>
<li><p>https://www.math.ucdavis.edu/~hunter/pdes/ch1.pdf</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="appendix-c-non-smooth-irregular-cont.-1" class="slide level2 center">
<h2>Appendix C: (Non-)Smooth, (Ir)Regular Cont.</h2>
<ul>
<li class="fragment"><p>Now, <span class="math inline">\(X\)</span> is just a realization of a stochastic process, and the condition is that we put an expectation over all realizations, and since we want to conduct statistical analysis we can’t use <span class="math inline">\(\le\)</span>, we instead must use <span class="math inline">\(\approx\)</span></p></li>
<li class="fragment"><p>You need equality in order to get estimates of <span class="math inline">\(H\)</span> and <span class="math inline">\(L\)</span> (if we don’t have equality, forget it), but the <em>good news</em> is that almost all the processes you find in probability texts do indeed satisfy the <em>almost equal</em> condition we use (e.g., derivatives, squares, log(1+…) for Gaussian processes do satisfy this with equality), so in fact there is no loss in generality and this is not restrictive at all</p></li>
<li class="fragment"><p>Furthermore, we adopt an augmented Hölder continuity condition and allow <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> to vary on <span class="math inline">\(t\in[0,1]\)</span>, thus we work with <span class="math display">\[\mathbb{E}\left[(X_u-X_v)^2\right]\approx L_t^2|u-v|^{2H_t},\quad u,v\text{ in some neighborhood of } t\]</span></p></li>
</ul>
<aside class="notes">
<ul>
<li><p>Here we use the Kolmogorov Continuity Theorem (video Mar 7 around 35 mins)</p></li>
<li><p>Let <span class="math inline">\((S,d)\)</span> be some complete metric space, and let <span class="math inline">\(X\colon [0, + \infty) \times \Omega \to S\)</span> be a stochastic process. Suppose that for all times <span class="math inline">\(T &gt; 0\)</span>, there exist positive constants <span class="math inline">\(\alpha,  \beta,  K\)</span> such that</p>
<p><span class="math display">\[\mathbb{E} [d(X_t, X_s)^\alpha] \leq K | t - s |^{1 + \beta}\]</span></p>
<p>for all <span class="math inline">\(0 \leq s, t \leq T\)</span>. Then there exists a modification <span class="math inline">\(\tilde{X}\)</span> of <span class="math inline">\(X\)</span> that is a continuous process, i.e.&nbsp;a process <span class="math inline">\(\tilde{X}\colon [0, + \infty) \times \Omega \to S\)</span> such that</p>
<ul>
<li><span class="math inline">\(\tilde{X}\)</span> is sample-continuous;</li>
<li>for every time <span class="math inline">\(t \geq 0\)</span>, <span class="math inline">\(\mathbb{P} (X_t = \tilde{X}_t) = 1.\)</span></li>
</ul></li>
<li><p>Furthermore, the paths of <span class="math inline">\(\tilde{X}\)</span> are locally <span class="math inline">\(\gamma\)</span>-Hölder-continuous for every <span class="math inline">\(0&lt;\gamma&lt;\tfrac\beta\alpha\)</span></p></li>
<li><p>NB - In our case (set <span class="math inline">\(\alpha=2\)</span>, “we like squares”), <span class="math inline">\(1+\beta=2H\)</span>, and <span class="math inline">\(K=L^2\)</span>… to obtain equality we let <span class="math inline">\(L^2\)</span> denote the infimum of <span class="math inline">\(K\)</span> such that equality holds</p></li>
<li><p>NB - our <span class="math inline">\(L\)</span> controls the signal-to-noise ratio (<span class="math inline">\(L\)</span>-to-<span class="math inline">\(\sigma\)</span> ratio). A larger <span class="math inline">\(L\)</span>, other things equal, means the signal is very informative as the amplitude of the oscillations is very large relative to the measurement error (around 56 mins into Mar 7 2023 video)</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="appendix-d-pointwise-local-curve-properties" class="slide level2 center">
<h2>Appendix D: Pointwise Local Curve Properties</h2>
<ul>
<li class="fragment"><p>The Hölder class MSE of one kernel smoothed curve at a point <span class="math inline">\(t\)</span>, where <span class="math inline">\(M_i\)</span> is the number of observations for the <span class="math inline">\(i\)</span>th curve, is given by <span class="math display">\[MSE_i\leq C_1(t)h^{2H_t}  + \frac{C_2(t)}{M_i f_T(t) h}\]</span></p></li>
<li class="fragment"><p>The constants in the above formula are <span class="math inline">\(C_1(t)=L_t^2\int |u|^{2H_t}|K(u)|du\)</span> and <span class="math inline">\(C_2(t)=\sigma^2_t \int K^2(u)du\)</span>, where <span class="math inline">\(K(u)\)</span> is the kernel function</p></li>
<li class="fragment"><p>Given this, the MSE-optimal bandwidth for curve <span class="math inline">\(i\)</span> at point <span class="math inline">\(t\)</span> is <span class="math display">\[h^*_t=\left[\frac{C_2(t)}{2H_tC_1(t)M_i f_T(t)}\right]^{\frac{1}{2H_t+1}}\]</span></p></li>
<li class="fragment"><p>Using the Epanechnikov kernel given by <span class="math inline">\(\frac{3}{4}(1-u^2)\)</span> on <span class="math inline">\([-1,1]\)</span>, it can be shown that <span class="math inline">\(C_1(t)=\frac{3L_t^2}{[2H_T+1][2H_t+3]}\)</span> and <span class="math inline">\(C_2(t)=\frac{3}{5}\sigma^2_t\)</span></p></li>
</ul>
</section>
<section id="appendix-e-estimation-of-sigma2_t" class="slide level2 center">
<h2>Appendix E: Estimation of <span class="math inline">\(\sigma^2_t\)</span></h2>
<ul>
<li class="fragment"><p>To construct a consistent estimator of <span class="math inline">\(\sigma^2_t\)</span> appearing in the MSE-optimal bandwidth formula, we use the following expression: <span class="math display">\[\begin{equation*}
\widehat\sigma^2_t=\frac{1}{2N}\sum_{i=1}^N\left(Y^{(i)}_{m(t)}-Y^{(i)}_{m(t-1)}\right)^2
\end{equation*}\]</span></p></li>
<li class="fragment"><p>To obtain this expression, let <span class="math inline">\(m(t)\)</span> denote the order statistic of discrete sample point <span class="math inline">\(m\)</span> indexed at <span class="math inline">\(t\)</span> (i.e., <span class="math inline">\(T^{(i)}_{m(t)}\)</span> is the closest sample design point to <span class="math inline">\(t\)</span>, <span class="math inline">\(T^{(i)}_{m(t-1)}\)</span> the second closest, etc.)</p></li>
<li class="fragment"><p>Recalling that <span class="math inline">\(\varepsilon^{(i)}_m = \sigma(T^{(i)}_m) e^{(i)}_m\)</span>, we can express <span class="math inline">\((Y^{(i)}_{m(t)}-Y^{(i)}_{m(t-1)})\)</span> in the expression above as follows: <span class="math display">\[\begin{align*}
Y^{(i)}_{m(t)}-Y^{(i)}_{m(t-1)}&amp;=X^{(i)}(T^{(i)}_{m(t)})+\varepsilon^{(i)}_{m(t)}-X^{(i)}(T^{(i)}_{m(t-1)})-\varepsilon^{(i)}_{m(t-1)}\\
&amp;=\left(X^{(i)}(T^{(i)}_{m(t)})-X^{(i)}(T^{(i)}_{m(t-1)})\right)+\left(\varepsilon^{(i)}_{m(t)}-\varepsilon^{(i)}_{m(t-1)}\right)
\end{align*}\]</span></p></li>
</ul>
</section>
<section id="appendix-e-estimation-of-sigma2_t-cont." class="slide level2 center">
<h2>Appendix E: Estimation of <span class="math inline">\(\sigma^2_t\)</span> Cont.</h2>
<ul>
<li class="fragment"><p>Given continuity of <span class="math inline">\(X^{(i)}(T^{(i)}_{m(t)})\)</span>, the first term on line 2 is negligible</p></li>
<li class="fragment"><p>Given this, and the independence of the <span class="math inline">\(e^{(i)}_{m(t)}\)</span>, we have <span class="math display">\[\begin{align*}
\mathbb{E}\left(Y^{(i)}_{m(t)}-Y^{(i)}_{m(t-1)}\right)^2
&amp;\approx\mathbb{E}\left(\varepsilon^{(i)}_{m(t)}-\varepsilon^{(i)}_{m(t-1)}\right)^2=2\sigma^2(t),
\end{align*}\]</span> which leads to the expression <span class="math inline">\(\widehat\sigma^2_t=\frac{1}{2N}\sum_{i=1}^N\left(Y^{(i)}_{m(t)}-Y^{(i)}_{m(t-1)}\right)^2\)</span></p></li>
<li class="fragment"><p>A similar approach has been used in a classical <em>homoscedastic</em> nonparametric setting <span class="citation" data-cites="horowitz_spokoiny:2001">(<a href="#/references-scrollable" role="doc-biblioref" onclick="">Horowitz and Spokoiny 2001</a>, Equation (2.9))</span></p></li>
<li class="fragment"><p>We modify this for use in an FDA setting, and by exploiting “replication” (i.e., by averaging vertically <em>over all curves</em> at point <span class="math inline">\(t\)</span>) we obtain a simple method for computing the measurement noise variance that allows for heteroscedasticity of unknown form</p></li>
</ul>
</section></section>
<section id="references-scrollable" class="title-slide slide level1 scrollable smaller">
<h1>References (scrollable)</h1>
<div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p>Locally Adaptive Online FDA | V. Patilea &amp; J. Racine</p>
</div>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-belhakem_et_al:2021" class="csl-entry" role="listitem">
Belhakem, Ryad, Franck Picard, Vincent Rivoirard, and Angelina Roche. 2021. <span>“Minimax Estimation of Functional Principal Components from Noisy Discretized Functional Data.”</span> https://doi.org/<a href="https://doi.org/10.48550/arXiv.2110.12739">https://doi.org/10.48550/arXiv.2110.12739</a>.
</div>
<div id="ref-cai_low_ma:2014" class="csl-entry" role="listitem">
Cai, T. Tony, Mark Low, and Zongming Ma. 2014. <span>“Adaptive Confidence Bands for Nonparametric Regression Functions.”</span> <em>Journal of the American Statistical Association</em> 109 (507): 1054–70.
</div>
<div id="ref-cai_yuan:2011" class="csl-entry" role="listitem">
Cai, T. Tony, and Ming Yuan. 2011. <span>“<span class="nocase">Optimal estimation of the mean function based on discretely sampled functional data: Phase transition</span>.”</span> <em>The Annals of Statistics</em> 39 (5): 2330–55. <a href="https://doi.org/10.1214/11-AOS898">https://doi.org/10.1214/11-AOS898</a>.
</div>
<div id="ref-chan_wood:1998" class="csl-entry" role="listitem">
Chan, Grace, and Andrew T. A. Wood. 1998. <span>“Simulation of Multifractional Brownian Motion.”</span> In <em>COMPSTAT</em>, edited by Roger Payne and Peter Green, 233–38. Heidelberg: Physica-Verlag HD.
</div>
<div id="ref-fda.usc" class="csl-entry" role="listitem">
Febrero-Bande, Manuel, and Manuel Oviedo de la Fuente. 2012. <span>“Statistical Computing in Functional Data Analysis: The <span>R</span> Package <span class="nocase">fda.usc</span>.”</span> <em>Journal of Statistical Software</em> 51 (4): 1–28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>.
</div>
<div id="ref-hall_horowitz:2007" class="csl-entry" role="listitem">
Hall, Peter, and Joel L. Horowitz. 2007. <span>“Methodology and Convergence Rates for Functional Linear Regression.”</span> <em>The Annals of Statistics</em> 35 (1): 70–91.
</div>
<div id="ref-horowitz_spokoiny:2001" class="csl-entry" role="listitem">
Horowitz, Joel L., and Vladimir G. Spokoiny. 2001. <span>“An Adaptive, Rate-Optimal Test of a Parametric Mean-Regression Model Against a Nonparametric Alternative.”</span> <em>Econometrica</em> 69 (3): 599–631.
</div>
<div id="ref-horvath_kokoszka:2012" class="csl-entry" role="listitem">
Horváth, Lajos, and Piotr Kokoszka. 2012. <em>Inference for Functional Data with Applications</em>. Vol. 200. Springer Series in Statistics. https://doi.org/<a href="https://doi.org/10.1007/978-1-4614-3655-3">https://doi.org/10.1007/978-1-4614-3655-3</a>.
</div>
<div id="ref-kokoszka_reimherr:2017" class="csl-entry" role="listitem">
Kokoszka, P., and M. Reimherr. 2017. 1st ed. Chapman; Hall/CRC. https://doi.org/<a href="https://doi.org/10.1201/9781315117416">https://doi.org/10.1201/9781315117416</a>.
</div>
<div id="ref-lepski_mammen_spokoiny:1997" class="csl-entry" role="listitem">
Lepski, O. V., E. Mammen, and V. G. Spokoiny. 1997. <span>“<span class="nocase">Optimal spatial adaptation to inhomogeneous smoothness: an approach based on kernel estimates with variable bandwidth selectors</span>.”</span> <em>The Annals of Statistics</em> 25 (3): 929–47. <a href="https://doi.org/10.1214/aos/1069362731">https://doi.org/10.1214/aos/1069362731</a>.
</div>
<div id="ref-levitin_et_al:2007" class="csl-entry" role="listitem">
Levitin, Daniel J., Regina L. Nuzzo, Bradley W. Vines, and James O. Ramsay. 2007. <span>“Introduction to Functional Data Analysis.”</span> <em>Canadian Psychology</em> 48: 135–55.
</div>
<div id="ref-padilla_segarra_et_al:2020" class="csl-entry" role="listitem">
Padilla-Segarra, Adrián, Mabel González-Villacorte, Isidro R. Amaro, and Saba Infante. 2020. <span>“Brief Review of Functional Data Analysis: A Case Study on Regional Demographic and Economic Data.”</span> In <em>Information and Communication Technologies</em>, edited by Germania Rodriguez Morales, Efraín R. Fonseca C., Juan Pablo Salgado, Pablo Pérez-Gosende, Marcos Orellana Cordero, and Santiago Berrezueta, 163–76. Cham: Springer International Publishing.
</div>
<div id="ref-peltier_vehel:1995" class="csl-entry" role="listitem">
Peltier, Romain-François, and Jacques Lévy Véhel. 1995. <span>“<span class="nocase">Multifractional Brownian Motion : Definition and Preliminary Results</span>.”</span> Research Report RR-2645. <span>INRIA</span>. <a href="https://hal.inria.fr/inria-00074045">https://hal.inria.fr/inria-00074045</a>.
</div>
<div id="ref-fda" class="csl-entry" role="listitem">
Ramsay, J. O., Spencer Graves, and Giles Hooker. 2022. <em>Fda: Functional Data Analysis</em>. <a href="https://CRAN.R-project.org/package=fda">https://CRAN.R-project.org/package=fda</a>.
</div>
<div id="ref-ramsay_silverman:2005" class="csl-entry" role="listitem">
Ramsay, J. O., and B. W. Silverman. 2005. <em>Functional Data Analysis</em>. 2nd ed. New York: Springer-Verlag.
</div>
<div id="ref-reiss_et_al:2017" class="csl-entry" role="listitem">
Reiss, Philip T., Jeff Goldsmith, Han Lin Shang, and R. Todd Ogden. 2017. <span>“Methods for Scalar-on-Function Regression.”</span> <em>International Statistical Review / Revue Internationale de Statistique</em> 85 (2): 228–49. <a href="http://www.jstor.org/stable/44840886">http://www.jstor.org/stable/44840886</a>.
</div>
<div id="ref-robbins_munro:1951" class="csl-entry" role="listitem">
Robbins, Herbert, and Sutton Monro. 1951. <span>“<span>A Stochastic Approximation Method</span>.”</span> <em>The Annals of Mathematical Statistics</em> 22 (3): 400–407. <a href="https://doi.org/10.1214/aoms/1177729586">https://doi.org/10.1214/aoms/1177729586</a>.
</div>
<div id="ref-tian_renfang:2020" class="csl-entry" role="listitem">
Tian, Renfang. 2020. <span>“On Functional Data Analysis: Methodologies and Applications.”</span> PhD thesis, UWSpace. <a href="http://hdl.handle.net/10012/15811">http://hdl.handle.net/10012/15811</a>.
</div>
<div id="ref-wang_chiou_muller:2016" class="csl-entry" role="listitem">
Wang, Jane-Ling, Jeng-Min Chiou, and Hans-Georg Müller. 2016. <span>“Functional Data Analysis.”</span> <em>Annual Review of Statistics and Its Application</em> 3 (1): 257–95. <a href="https://doi.org/10.1146/annurev-statistics-041715-033624">https://doi.org/10.1146/annurev-statistics-041715-033624</a>.
</div>
<div id="ref-fdapace" class="csl-entry" role="listitem">
Zhou, Yidong, Satarupa Bhattacharjee, Cody Carroll, Yaqing Chen, Xiongtao Dai, Jianing Fan, Alvaro Gajardo, et al. 2022. <em>Fdapace: Functional Data Analysis and Empirical Dynamics</em>. <a href="https://CRAN.R-project.org/package=fdapace">https://CRAN.R-project.org/package=fdapace</a>.
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="index_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="index_files/libs/revealjs/plugin/multiplex/socket.io.js"></script>
  <script src="index_files/libs/revealjs/plugin/multiplex/multiplex.js"></script>
  <script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="index_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="index_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="index_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'multiplex': {"secret":null,"id":"3848493eef10d12f","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
              // target, if specified
              link.setAttribute("target", "_blank");
              if (link.getAttribute("rel") === null) {
                link.setAttribute("rel", "noopener");
              }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    

</body></html>